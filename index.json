[{"categories":null,"content":"0 序言 历时两天，终于把我人生中的第一台主机装好了。这个过程中也走了不少弯路，受了许多累，现在趁着我的大脑还没把装机的过程忘光，在此做一下记录与反思，以供未来装机参考，亦可供在座诸位消磨时光。 注意 我这次装机基本流程是按照B站硬件茶谈的动画装机教程来的，这个装机教程做得确实好，让我在装机开始之前就基本做到了心中有数（在此之前，我可是连主机的基本构成都讲不明白的硬件小白）。尽管如此，我在装机的过程中仍然遇到了相当大的阻力，这也是我写这篇文章的初衷，记录下我在这次装机中走过的弯路，警示未来的自己。 另外，由于在装机过程中出现了意外状况，实际装机顺序并未完全按照硬件茶谈的教程来走，这同样也为装机过程增添了许多困难。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:1:0","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"为什么想要装机 与很多大学生一样，自己组一台电脑是我自上大学以来就想干的事，不过一直以来，这个梦想都没有能实现。正巧最近手里有点闲钱，一直用的轻薄本总有充不进去电的毛病（后来被我换个电池修好了），自己想打的游戏又由于配置原因带不动，于是萌生了换一台电脑的想法。本来是想换一台笔记本的，但挑着挑着总感觉价格太贵，拎着太沉，散热太差，况且自己的老本子才刚修好，和朋友商量了之后，决定装一台主机。 这台机器是我看了一个星期的各种装机攻略和教程，独自选出来的配置，由于经验不足、时间仓促、预算有限，我的配置一定既不是性能最好的，也不是最有性价比的，在实际使用中也有多多少少的一些问题，但这些对我来说都不是很重要，重要的是，我收获了动手装机的快乐，获得了一次难忘的体验，并且有信心在未来做得更好。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:1:1","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"配置 本次装机的配置如下（所有配件均购买自京东）： 分类 产品 价格 CPU 英特尔 i5-12400f 659 主板 七彩虹 H610M-E 459 显卡 磐镭 鳞甲RX6650XT 1489 内存 金百达 DDR4 3200 银爵 8GB × 2 189 硬盘 铠侠 RC20 1T 419 散热 利民 AX120R SE 68 电源 利民 TG650 650W 309 机箱 玩嘉 阿尔法S1 236 显示器 三星 LS24D360G 1K 100Hz VA面板 629 合计 4457 警告 由于笔者惫懒，本文中将不会出现实拍图片，敬请谅解。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:1:2","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"第一天 在等待了两三天全部配件到齐之后，我在一个风和日丽的下午开始了我的装机之旅。当天下午2:30，我从防静电袋里拿出了主板（由于一开始买的显示器效果不佳，我重新下单了现在这个三星的显示器。在开始装机前，我刚刚完成了显示器的更换和测试。这个暂时按下不表）。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:0","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"CPU、内存、硬盘 安装CPU、内存和硬盘总共也没用上5分钟。随后我打算先将主板安到机箱背板上，接了供电线，然后再安装散热（这是因为我听说安完散热之后，CPU供电线就不好接了）。然而，让我没想到的是，机箱背板上的螺丝柱我拧不动！玩嘉阿尔法S1的机箱背板上有自带6个螺丝柱，其中有5个位置和我的主板匹配，不需要动。只有一个螺丝柱位置偏下，在主板外侧。我要么将它上移到主板对应的螺丝孔位，要么拿一个新的螺丝柱安在对应的孔位上，但这两件事我都做不到，因为机箱既没有配备六角螺丝套筒，我也没有准备扳手或钳子。所以我既没法把原有的螺丝柱拧下来，也没法用新的螺丝柱拧上去。 在跟螺丝柱抗衡了20来分钟后，我两臂战战，手指酸痛。我意识到，没有工具的我是没可能完成这项工作了。于是我立即下单了一个钳子，并重新安排了装机计划。我决定先不管机箱了，在机箱外先把配件都装上，给他点亮，等明天钳子到了再装箱。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:1","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"散热、显卡 随后就是装散热和显卡，没什么复杂的。值得一提的是，在做攻略的时候，很多人都提到散热鳍片很锋利，容易把手划伤。我没准备手套，所以在拿散热的时候总是小心翼翼的，生怕把手划了。直到散热快装完了都没出事，结果在拧弹簧螺丝的时候大意，划到了手背。一开始我都没注意到，安完了之后翻过手背一开，已经淌了不少血了，也弄到鳍片上一些，好在发现得不晚，要是滴到主板上可就寄了。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:2","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"电源接线 配件安好后，该连电源线了。掏出模组线理一理，发现我只需要CPU、主板和显卡三条供电线，十分简单，除了主板的24Pin比较难插之外，很快就搞定了。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:3","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"点亮 连接好电源和显示器后，我打开了电源的开关，发现风扇没转，我心理咯噔一下。怎么回事呢，是哪里出问题了导致没点亮吗，那可就麻烦了。于是我仔细回忆了一下，感觉还缺一个开机的动作来着。我看着面前的主板，沿着四周左右找找，也没发现开机的按钮啊，这该咋开机呢？上网搜索后，才得知，用螺丝刀将Power Switch的两个针脚短接后，就可以开机了！这是我在装机视频中不曾看过的知识，现在分享给大家。我拿螺丝刀轻轻一碰，风扇就开始呼呼转了起来。至此，我的初步装机计划基本完成。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:4","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"装系统和驱动 点亮后，用系统盘装系统以及安装驱动的流程可以从硬件茶谈的另外两个视频中了解：WIN10系统安装教程，驱动安装教程 。比较简单，一直点下一步就行。 事实上，现在的机器已经基本可用了（而且十分小巧轻便）。不过，为了避免精密零件收到不必要的损害，还是把它们装到箱子里比较保险。目前为止，整个过程用了我大约2小时的时间。接下来就开始我第二天装机箱的痛苦旅程吧。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:5","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"小结 因为缺乏工具，无法将主板安上机箱，我不得不在机箱外先尝试点亮。事实上，我不仅没有钳子，甚至连螺丝刀都是用的我在给笔记本换电池时商家送的小螺丝刀套装（在淘宝买的大螺丝刀迟迟不到）。在装机前拆机箱前后挡板时我就已经经历了拧不动螺丝的痛苦，第二天在装机箱的过程中遇到的麻烦更加深了这种痛苦。在各种装机视频中很少提到需要什么工具（可能大家都认为是常识，一开始我也以为是常识），也不曾强调哪些工作实际上是很困难的（拧个螺丝谁来都行？事实上人和人的体质不能一概而论）。因此，在之后装机时，我至少要准备一把长螺丝刀和一把钳子，如果能有一个电动螺丝刀用来装机箱的话，那真的会为装机带来很美好的体验！ ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:2:6","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"第二天 在第一天的时候，我已经成功在机箱外完成了电脑的组装，并成功点亮。当天晚上，完成了系统和驱动的安装后，我简单对各个硬件进行了测试和跑分，分数中规中矩吧，毕竟是这个预算和配置。烤鸡时，CPU功耗被限制在65W，温度才50度多一点，应该是被主板限制功耗墙了。显卡能给到143W，甜甜圈帧率能到320左右，温度大概74度。这是没有机箱纯暴露在空气中获得的温度，放进机箱后大概要升高个5到10度。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:3:0","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"进机箱 在快递的钳子终于到了之后，我能够拧下那个令我头痛的螺丝柱，我的装机之旅的第二部分才正式拉开序幕。 我的初步想法是，由于插主板的线实在不太好插拔，于是保留不动，拆电源那边的接口，把主板放进机箱，再接电源，就可以简单搞定了。想法很美好，但操作起来却遇到了很多问题。 首先，我必须先把显卡拔下来。因为它庞大的身躯挡住了我主板上的一个螺丝孔。然而，要拆显卡，需要把藏在显卡下面的一个小小的卡扣掰开，然后才能把显卡拔下来。我从上方望下去，那个卡扣绝大部分都藏在显卡的下面，只在显卡和散热的缝隙中露出了一点点边。我冒着再次被散热割伤的风险把手指塞进缝隙里尝试了几次，缝隙太窄，很难使上力。无奈，我只得把散热先拆下来，再去掰那个卡扣。 终于，拆掉显卡和散热的主板被我有惊无险地放进了机箱。简单地拧好螺丝之后，主板就固定在了机箱上。随后我又依照第一天的经验把散热和显卡重新安装上，当然，安装散热之前重新涂了硅脂。尽管有着装过一次的经验，但在机箱狭小的空间中，螺丝也不是那么好拧了。这时我突然理解为什么有些装机佬要准备那么长的螺丝刀了，拧塔式散热的螺丝是真卡手啊。 随后在拆机箱显卡的IO挡板以及电源框架的时候又遇到了拧螺丝的阻力。简单来说，螺丝又拧不动了。我承认没怎么干过粗活的我确实在这没什么技术含量的工作上受苦了，不过办法总比困难多。在尝试了若干次无果之后，我终于拿出了一个在此后无往而不利的撒手锏，那就是——用我的钳子钳住我的小螺丝刀来拧螺丝！用了这个方法之后，除了有点费事外，再紧的螺丝都不是我一合之敌。 装完显卡，插上电源线之后，最后一步是接机箱的IO线。其实这本该在装显卡之前接的，但我疏忽了，导致底部控制开机、重启那几根线死活也接不上去。在显卡和机箱底部的卡位之下，操作的空间微乎其微。不得已，我需要再一次拆除显卡。但读过前文的朋友应该注意到，要拆显卡还需要拆散热，难道我还要再拆一次散热吗？我受不了再拆一次散热的折磨，于是这次我狠下心来把手塞进显卡和散热之间的缝隙中去摁那个卡扣，在调整了几番姿势后，居然真让我摁开了。在拆下显卡后，机箱IO的线也终于是接上了。可喜可贺。 我遇到的最后一个难关就是机箱风扇的安装。不记得我有没有提到过，因为配置发热不高，以及为了省点事，我只准备安装一个风扇在机箱尾部。因此，我没有接线和理线方面的问题。唯一称得上问题的是，这个风扇配备的是自攻螺丝，非常难拧。哈哈，各位是不是已经猜到了，没错，我在整个装机过程中遇到的绝大多数困难都是拧不动螺丝，这是一个非常现实的问题。因为其实装机并不是一个非常需要技术的活，相比于那些专业干这个的，普通人在装机时遇到最多的问题往往还是缺乏趁手的工具，没办法很轻松地拧好这些螺丝。好在我还有我的钳子螺丝刀合二为一的撒手锏，靠着这个，我花了大概十分钟拧上了一个风扇的四个螺丝。 将机箱的前后背板安装上后，整个装机算是大功告成了。我心潮澎湃地按下开机键，很快，风扇呼呼地转了起来，显示器上出现了Win10的经典蓝色背景。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:3:1","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"总结 多的就不说了，是一次难忘的体验，如果还有下次，我会提前买一个电动螺丝刀。 ","date":"2025-03-08","objectID":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/:4:0","tags":["装机"],"title":"人生第一次装机","uri":"/%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%A3%85%E6%9C%BA/"},{"categories":null,"content":"数据并行的核心思想是：在每个GPU上都拷贝一份完整模型，每个模型副本各自输入一份数据，计算一份梯度，最后对梯度进行累加来更新整体模型。理念并不复杂，但到了大模型场景，如何处理巨大的存储和GPU之间的通信，就是系统设计要考虑的重点了。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:0:0","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1 数据并行（DP） ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:1:0","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1.1 整体架构 是最早的数据并行模式，采用参数服务器（Parameter Server）架构，实际用于单机多卡。 典型的数据并行流程如下： 模型复制：数据并行使用多个计算节点，每个计算节点保存一份相同的完整模型副本。 数据分割：将训练数据batch均匀分割成多个mini-batches，每个mini-batch分配给一个计算节点。 前向和反向计算：每个计算节点使用其分配到的mini-batch进行前向和反向计算，得到一份梯度。 梯度聚合：每个计算节点将自己计算的梯度发送到一个Server节点（一般选择一个计算节点同时作为Server），执行梯度聚合操作。这里的聚合操作一般指梯度累加，也可由用户自定义。 参数更新：Server节点完成梯度聚合后，用完整的梯度更新模型参数，再将更新后的参数广播给所有计算节点。 将梯度聚合再下发的操作，称为All-Reduce。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:1:1","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1.2 参数服务器 参数服务器（Parameter Server）是一种分布式系统架构，专门用于大规模机器学习任务。 在该架构中包含两个角色：Worker和Server。Worker充当计算节点负责模型训练，而Server负责梯度聚合和参数更新。在实际应用中，为了尽量减少通信量，一般可选择一个Worker同时作为Server，比如可以把梯度发到GPU0上做聚合。 为了保持模型一致性，一般有两种方法： 将模型参数保存在一个集中的节点上，当一个计算节点要进行模型训练时，可从集中节点获取参数，进行模型训练，然后将更新后的模型推送会集中节点。由于所有计算节点都从同一个集中节点获取参数，因此可以保证模型一致性。 每个计算节点都保存模型参数的副本，因此要定期强制同步模型参数副本。每个计算节点使用自己的训练数据分区来训练本地模型副本。在每个训练迭代后，由于使用不同的输入数据进行训练，存储在不同计算节点上的模型副本可能会有所不同。因此，每一次训练迭代后插入一个全局同步的步骤，这将对不同计算节点上的参数进行平均，以便以完全分布式的方式保证模型的一致性，即All-Reduce范式。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:1:2","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1.3 通信瓶颈与梯度异步更新 DP的框架在实战中有两个主要问题： 存储开销大。每块GPU上都保存了一份完整的模型，造成冗余。 通信开销大。Server需要和每一个Worker进行梯度传输。当Server和Worker不在一台机器上时，Server的带宽将会成为整个系统的计算效率瓶颈。 梯度异步更新要求每个GPU计算完梯度后，无需等待其他GPU更新，立即更新整体权重。并且，每个GPU并不空置等待权重更新的结果，而是直接使用未更新的权重参数进行下一轮mini-batch训练。所以其本质上相当于增加了batch size，在SGD下会减缓模型的收敛速度，并且由于异步会产生复杂的梯度问题。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:1:3","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2 分布式数据并行（DDP） 分布式数据并行，采用Ring All-Reduce的通信方式，实际中多用于多机场景。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:2:0","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2.1 Ring All-Reduce PS架构中，当worker数量较多时，PS节点的网络带宽将成为系统的瓶颈。 All-Reduce架构是指不带有参数服务器的分布式集群架构。在该架构中，集群的所有节点都作为worker来执行计算操作，该架构会在每个batch训练完成后，使用All-Reduce算法在所有worker节点间进行模型变量的同步更新。 传统的同步更新方法（各个GPU卡算好梯度，求和算平均的方式），在融合梯度时，会产生巨大的通信数据量，这种通信压力往往在模型参数量很大时，显得很明显。因此我们需要找到一种方法，来解决同步更新的网络瓶颈问题。其中最具代表性的一种方法就是Ring All-Reduce。 Ring All Reduce是一种以环状拓扑为基础的通信系统。Ring All-Reduce架构中各个设备都是worker，没有中心节点来聚合所有worker计算的梯度。Ring All-Reduce算法将 device 放置在一个逻辑环路（logical ring）中。每个 device 从上行的device 接收数据，并向下行的 deivce 发送数据，因此可以充分利用每个 device 的上下行带宽。 梯度聚合过程分为两个阶段： Reduce-Scatter：GPU会逐步交换彼此的梯度并聚合，最后每个GPU会包含完成聚合梯度的一部分。 All-Gather：GPU会逐步交换彼此不完整的聚合梯度，最后所有GPU都会得到完整的聚合梯度。 Reduce-Scatter 每个节点把本设备上的数据分成N块，N是架构中worker的数目。 在一次传输和接收结束后，在每个节点上累加了其他节点的一个块的数据。这样的数据传输模式直到阶段结束。 每个节点上都有一个包含最后结果的块，这个块的数据是所有节点相应位置块数据之和。 All-Gather All Gather阶段总共包含N-1次数据传输，不同的是，All Gather阶段并不需要将接收到的值进行累加，而是直接使用接收到的块内数值代替原来块中的值。在一次传输后，每个节点含有最终结果的块增加一个。 继续这个传输过程直到结束，使得每个节点都包含了全部的数据结果。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:2:1","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2.2 Ring All-Reduce通信量分析 假设模型参数大小为 $\\Phi$ ，GPU个数为 $N$ 。则梯度大小也为 $\\Phi$ ，每个梯度块的大小为 $\\frac{\\Phi}{N}$ 。对单卡GPU来说（只计算其发送通信量），Reduce-Scatter阶段的通信量为 $(N - 1) \\frac{\\Phi}{N}$ ，All-Gather阶段的通信量为 $(N - 1) \\frac{\\Phi}{N}$ 。单卡通信量为 $2(N - 1) \\frac{\\Phi}{N}$，随着 $N$ 的增大，可以近似为 $2\\Phi$ ，全卡总通信量为 $2N\\Phi$。 而对于PS架构，Server承载的通信量为 $N\\Phi$，Workers的总通信量为 $N\\Phi$ ，全卡通信量也为 $2N\\Phi$ 。 虽然通信量相同，但Ring All-Reduce架构将通信量均衡负载到了每一时刻的每个Worker上，而PS架构的负载集中于Server。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:2:2","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3 ZeRO ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:3:0","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3.1 存储消耗 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:3:1","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3.2 ZeRO-DP $P_{os}$ 将优化器状态（Optimizer States）分成若干份，每块GPU上各维护一份。 每个GPU上的进程完成一轮forward和backward后，各算得一份Local梯度。对梯度做All Reduce，得到聚合后梯度G。 梯度和部分优化器状态更新部分参数，再做All Gather获得完整参数W。 $P_{os + g}$ 更进一步，将梯度也拆分，每个GPU各维护一份梯度。 每个GPU上的进程完成一轮forward和backward后，各算得一份Local梯度。由于GPU只需要维护自己那部分梯度，所以做Reduce Scatter将部分梯度做聚合。 使用部分梯度和部分优化器状态更新部分参数，再做All Gather获得完整参数W。 $P_{os + g + p}$ 将参数也切分成若干份，每个GPU上维护一份参数。 每个GPU进程在forward时对W做All Gather来获得完整参数参与计算。在backward时也对W做All Gather，取到完整的参数W。 做完backward，算得梯度G。对G做Reduce Scatter来聚合部分梯度。 使用部分梯度和部分优化器状态更新部分参数，由于只维护部分参数W，无需再进行通讯。 使用ZeRO2（$P_{os + g}$）时的通信量与普通DP的通信量一致，因为All Reduce就是这么实现的（All Reduce = Reduce Scatter + All Gather）。 将参数也切分后，会引入额外的通信，属于用通信来换内存。（通信量由$2\\Phi$增加到 $3\\Phi$ ，增加到1.5倍） ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:3:2","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3.3 ZeRO-R Activation 对Activation的拆分主要用于张量并行（Megatron-LM）。在张量并行中，尽管将参数拆分到不同的GPU上，但输入向量（Activation）还是要完整地在每个GPU上复制一份。ZeRO采用与前面类似的方式，将Activation做拆分，每个GPU上维护一份Activation。 在forward时，通过All Gather获得完整的Activation来参与计算。计算完成后，TP节点之间通过All Reduce来聚合输出，同样，由于每个GPU上只需要保存部分Activation，可以使用Reduce Scatter来聚合。 在backward时，做All Gather获得完整的Activation来进行计算。 Buffer 设置合适的、固定大小的buffer。 Memory Fragmentation 根据张量的生命周期管理和重整内存。 ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:3:3","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"X 参考 图解大模型训练之：数据并行上篇(DP, DDP与ZeRO) Scaling Distributed Machine Learning with the Parameter Server 图解大模型训练之：数据并行下篇( DeepSpeed ZeRO，零冗余优化) ZeRO: Memory Optimizations Toward Training Trillion Parameter Models ","date":"2025-01-22","objectID":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/:4:0","tags":["distributed training"],"title":"数据并行","uri":"/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1 Megatron-LM 张量并行是由Nvidia团队在Megatron-LM一文中提出的，针对Transformer模型训练的模型并行（文中称之为Model Parallelism）。事实上张量并行也属于模型并行，与GPipe提出的按照模型的层横向切分不同，张量并行将模型的参数纵向切分，分别放到不同的GPU上并行计算，然后再做聚合。 Megatron-LM提出的模型并行（张量并行）提供了将Transformer的各个层垂直切分的方法。 ","date":"2025-01-22","objectID":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/:1:0","tags":["distributed training"],"title":"张量并行","uri":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1.1 MLP ","date":"2025-01-22","objectID":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/:1:1","tags":["distributed training"],"title":"张量并行","uri":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1.2 Self Attention ","date":"2025-01-22","objectID":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/:1:2","tags":["distributed training"],"title":"张量并行","uri":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1.3 Embedding Word Embedding是一个 $v \\times h$ 的字典，其中 $v$ 可能很大，因此按 $v$ 进行拆分，放在不同的GPU中。 输入Embedding是一个查字典的过程，输入X分别到多个GPU上去查每个GPU上维护的那部分Embedding，然后通过All Reduce聚合。 输出Embedding是一个Linear层，按照MLP中的方法进行计算和聚合。 ","date":"2025-01-22","objectID":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/:1:3","tags":["distributed training"],"title":"张量并行","uri":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"X 参考 图解大模型训练之：张量模型并行(TP)，Megatron-LM Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism ","date":"2025-01-22","objectID":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/:2:0","tags":["distributed training"],"title":"张量并行","uri":"/%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"优化目标 做分布式训练的总体目标是什么？ 能训练更大的模型。 理想状况下，模型的大小和GPU的数量成线性关系。即GPU量提升x倍，模型大小也能提升x倍。 能更快地训练模型。 理想状况下，训练的速度和GPU的数量成线性关系。即GPU量提升x倍，训练速度也能提升x倍。 这是目标，也是难点。难点在于： 训练更大的模型时，每块GPU里不仅要存模型参数，还要存中间结果（用来做Backward）。而更大的模型意味着需要更多的训练数据，进一步提高了中间结果的大小。加重了每块GPU的内存压力。我们将在下文详细分析这一点。（对应着GPU中的内存限制） 网络通讯开销。数据在卡之间进行传输，是需要通讯时间的。不做设计的话，这个通讯时间可能会抹平多卡本身带来的训练速度提升。（对应着GPU间的带宽限制） ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:1:0","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"1 朴素的流水线并行 当你有一个单卡装不下的大模型时，一个直接的解决办法是，把模型隔成不同的层，每一层都放到一块GPU上。此时，模型做一轮forward和backward的过程如下： 其中下标表示batch编号，这里只有一个batch，因此下标都是0。每一行表示一个GPU，每一列表示timestep。 这张图的含义是：我在GPU0上做完一次forward，然后将GPU0上最后一层的输入传给GPU1，继续做forward，直到四块GPU都做完forward后，我再依次做backward。等把四块GPU上的backward全部做完后，最后一个时刻我统一更新每一层的梯度。 这样做确实能训更大的模型了，但也带来了两个问题： GPU利用度不够。 中间结果占据大量内存。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:2:0","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2 GPipe ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:3:0","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2.1 切分micro-batch 将输入的数据mini-batch再细分为micro-batch，在GPU间流水训练，以减少流水线bubble的占比。 图中，每个函数的第一个下标表示GPU编号，第二个下标表示micro-batch编号。若micro-batch的数量为$\\boldsymbol{M}$，使用GPU的数量为$\\boldsymbol{K}$，则GPipe通过实验证明，当 $\\boldsymbol{M \\ge 4 \\times K}$ 时，bubble产生的空转时间占比对最终训练时长的影响是微小的，可以忽略不计。 在前向计算中，$\\boldsymbol{M}$ 个micro-batch流水地通过$\\boldsymbol{K}$ 个GPU。在反向计算中，每个micro-batch的梯度基于forward的模型参数来计算，在所有micro-batch的梯度计算完成后，将梯度累加起来并用于更新所有GPU上的模型参数。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:3:1","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2.2 re-materialization 为了减少激活内存占用，GPipe在forward过程中，每个GPU只保存当前stage最后的输出，而不保存stage内部层间的activation。在backward时， 每个GPU再重新计算一遍forward来得到梯度。 采用这种方法，对于层数为$\\boldsymbol{L}$，mini-batch size为$\\boldsymbol{N}$，micro-batch的数量为$\\boldsymbol{M}$，使用GPU的数量为$\\boldsymbol{K}$ 的GPipe流水线并行来说，峰值显存占用从$\\boldsymbol{O(N \\times L)}$ 减小到$\\boldsymbol{O(N + \\frac{L}{K} \\times \\frac{N}{M})}$ 。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:3:2","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"2.3 GPipe流水线存在的问题 反向计算在全部前向计算完成后才开始，造成bubble时间。 需要缓存$\\boldsymbol{M}$ 份activation，显存占用较高。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:3:3","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3 PipeDream ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:4:0","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3.1 1F1B PipeDream的1F1B策略既可以减少bubble，又能缓解激活显存占用问题。 在开始阶段（startup phase），输入若干micro-batch（micro-batch的数量是在稳定阶段下保持流水线满负荷所允许的最小micro-batch数量），进行前向计算。当最后一个stage完成一个micro-batch的前向计算后，就立即进行该micro-batch的反向计算，随后交替地执行micro-batch的前向和反向计算。不是等待所有micro-batches全部执行完前向计算后再执行反向计算，而是在一个micro-batch前向计算完成后就立即执行反向计算，这样就可以尽早地开始执行反向计算，从而减少每个activation在显存中的保留时间。 在稳定阶段（steady phase），每个GPU交替执行前向和反向计算，这样使得每个GPU上都会有一个micro-batch正在处理，没有GPU空闲，从而保证获得资源的高利用率。 在通信方面，与GPipe的同步通信不同，PipeDream各个stage之间的通信与forward和backward计算是异步的，可以有效进行计算和通信重叠。如下图所示，当一个stage前向计算完成后，将activation传给后一个stage的通信与下一个time step进行的反向计算重叠。当反向计算完成后，将gradient传给前一个stage的通信与下一个time step的前向计算重叠。 PipeDream的权重更新是在每个mini-batch完成一次forward和backward计算后立即更新的。但这种流水线会导致forward和backward使用的参数版本不一致。比如上面流水线的图，对于Machine 1（stage 1）mini-batch 5 的前向计算是在mini-batch 1完成计算后更新的参数，而mini-batch 5的反向计算是在mini-batch 2、3、4更新后的参数。PipeDream提出了两种方法解决参数不一致的问题。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:4:1","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"3.2 Weight Stashing 和 Vertical Sync Weight stashing 为每个活跃的mini-batch维护了一个权重版本。当一个mini-batch进入流水线执行前向计算时，每个stage使用最新版本的权重进行计算，并将该版本权重作为该mini-batch的中间状态的一部分保存。当执行该mini-batch的反向计算时，使用同版本的权重来计算梯度。Weight stashing 确保在一个stage的计算中，一个mini-batch的前向和后向计算使用的是相同版本的权重，但并不对不同stage上使用权重的一致性有保证。 Vertical Sync 确保了跨stage的权重一致性。每个mini-batch在所有stage上的前向和反向计算均使用它进入流水线时的最新权重，比如mini-batch 5 的全程计算均使用mini-batch 1 训练更新后的权重参数。 Weight stashing 对有效训练有很大作用，而根据PipeDream的实验，是否使用Vertical Sync 对训练的影响可以忽略不计。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:4:2","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"4 Interleaved 1F1B Interleaved 1F1B使用了Virtual Pipeline Parallelism的方法，每个流水线阶段被进一步细分为更多的虚拟阶段（Virtual stage），每个实际GPU负责处理多个虚拟阶段。micro-batches在虚拟阶段中计算。 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:5:0","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"X 参考 图解大模型训练之：流水线并行（Pipeline Parallelism），以Gpipe为例 GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism PipeDream: Fast and Efficient Pipeline Parallel DNN Training [源码解析] 深度学习流水线并行 PipeDream(6)— 1F1B策略 ","date":"2025-01-15","objectID":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/:6:0","tags":["distributed training"],"title":"流水线并行","uri":"/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C/"},{"categories":null,"content":"本文介绍Markdown常用语法。 ","date":"2025-01-13","objectID":"/markdown/:0:0","tags":["tools"],"title":"Markdown","uri":"/markdown/"},{"categories":null,"content":"1 基本语法 ","date":"2025-01-13","objectID":"/markdown/:1:0","tags":["tools"],"title":"Markdown","uri":"/markdown/"},{"categories":null,"content":"1.1 标题 将 # 放在标题前来设置标题。# 的数量代表标题的级别。 ","date":"2025-01-13","objectID":"/markdown/:1:1","tags":["tools"],"title":"Markdown","uri":"/markdown/"},{"categories":null,"content":"1.2 强调 **粗体**：粗体 *斜体*：斜体 ***粗斜体***：粗斜体 ~~删除线~~：删除线 \u003cu\u003e下划线\u003c/u\u003e：下划线 ","date":"2025-01-13","objectID":"/markdown/:1:2","tags":["tools"],"title":"Markdown","uri":"/markdown/"},{"categories":null,"content":"1.3 引用 将 \u003e 放在要引用的文字前面来获得引用块。 ","date":"2025-01-13","objectID":"/markdown/:1:3","tags":["tools"],"title":"Markdown","uri":"/markdown/"},{"categories":null,"content":"1.4 代码 使用反引号 ` 包裹文字来表示代码。 使用双反引号 `` 包裹的文字中可以含有反引号。 使用三个反引号 ```创建代码块。 ","date":"2025-01-13","objectID":"/markdown/:1:4","tags":["tools"],"title":"Markdown","uri":"/markdown/"},{"categories":null,"content":"1 深度神经网络训练过程 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:1:0","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"1.1 深度神经网络 深度神经网络由若干层堆叠而成，每层由如下式子计算： $$\\boldsymbol{z = W \\cdot x + b}$$ $$\\boldsymbol{a} = f(\\boldsymbol{z})$$ 其中，$\\boldsymbol{x}$ 是输入，$\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 是权重，$f$ 是激活函数（Activation Function）。 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:1:1","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"1.2 前向传播 由输入经过多层神经网络到输出的计算过程。 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:1:2","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"1.3 反向传播 从后向前更新各层的权重的过程。 损失函数（Loss Function）$\\boldsymbol{L}$ 计算前向传播的输出值与真实值之间的差距。利用链式法则从后往前计算损失函数对每层权重的偏导数（梯度），并按照如下公式更新权重： $$\\boldsymbol{W = W - \\alpha \\dfrac{\\partial{L}}{\\partial{W}}}$$ $$\\boldsymbol{b = b - \\alpha \\dfrac{\\partial{L}}{\\partial{b}}}$$ 其中，$\\alpha$ 是学习率，表示权重更新的速度。 权重沿着梯度方向下降，因此又称为梯度下降法（Gradient decent）。 注意，在应用链式法则计算权重梯度时，对当前层权重梯度的计算可转化为当前层输出的函数，即： $$\\boldsymbol{\\dfrac{\\partial{L}}{\\partial{W_l}} = \\delta a_l}$$ 所以，反向传播计算依赖于前向传播过程中计算并保存的中间层输出。 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:1:3","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"2 分布式训练 分布式训练（Distributed Training）是指将训练任务分解成多个子任务，并在多个计算设备上并行地进行训练。 分布式训练系统的目标就是将单节点模型训练转换成等价的分布式并行模型训练。对于大语言模型来说，训练过程就是根据数据和损失函数，利用优化算法对神经网络模型参数进行更新的过程。 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:2:0","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"2.1 3D并行 2.1.1 数据并行（DP） 将同样的模型复制到多个计算设备上，每个计算设备都拥有一个模型副本（Model replica）。计算时，每个计算设备处理输入batch的一个子集，相当于沿batch维度对训练过程进行并行化。假设输入batch size 为N，计算设备数量为M，则每个计算设备会分配到N/M个样本。 每个模型副本使用分配到的batch进行前向计算，前向计算完成后，每个计算设备会根据本地的样本计算损失，得到梯度 $\\boldsymbol{G_i}$ （ $i$ 为设备编号），并将本地梯度进行广播。所有计算设备需要聚合其他设备的梯度值，计算出平均梯度 $(\\sum_{i = 1}^{N}\\boldsymbol{G_i}) / N$ 来更新参数，完成这个batch的训练。 与单设备训练相比，数据并行训练最主要的区别在于反向计算中的梯度需要在所有计算设备之间同步，以保证每个计算设备上最终得到的是所有模型副本上梯度的平均值。由于基于Transformer架构的大语言模型中每个算子都是依赖单个数据而非整个批次数据，因此，数据并行并不会影响其计算逻辑。一般情况下各计算设备中前向计算是相互独立的，不涉及同步问题。 数据并行的优缺点 数据并行可以通过增加计算设备数量，提升整体训练吞吐量，提升gbsps（Global Batch Size per Second），具有很高的加速比，但需要在每个计算设备上加载一份模型副本，显存占用较高。 2.1.2 张量并行（TP） 张量并行通过将模型的张量操作分割成多个子操作，并将这些子操作分配到不同的计算设备上，从而实现并行计算。 张量并行优缺点 与传统的模型并行相比，张量并行的粒度更细，可以在更高效利用计算资源的同时减少通信开销。 2.1.3 流水线并行（PP） 将模型的层拆分到多个计算设备上进行计算，每个设备上分得的层称为一个stage。流水线并行需要在计算节点之间通信，将前一个stage的输出作为后一个stage的输入，使得前后stage能够流水式地、分批地进行工作。流水线并行将模型分成多个stages，每个stage分配到不同的计算设备上，然后将数据以流水线的方式在各个设备之间传递，从而实现并行计算。 每个stage包含模型的一部分层或子模块，输入数据的mini-batches被细分成多个micro-batches，每个micro batch在流水线的一个stage上进行计算，然后依次传递到下一个stage。 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:2:1","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"X 参考 2.3. 深度学习——Python数据科学加速 一文弄懂神经网络中的反向传播法——BackPropagation 理论+实践，带你了解分布式训练 ","date":"2025-01-13","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/:3:0","tags":["distributed training"],"title":"分布式训练","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"},{"categories":null,"content":"本文简要记录使用Github Pages与Hugo构建个人博客的流程。 ","date":"2025-01-12","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:0:0","tags":["Blog"],"title":"使用Hugo构建个人博客","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"1 创建Github Pages Repo 这个步骤比较简单，只需要创建一个名为yourname.github.io的repo即可。（yourname为你的github账户名） ","date":"2025-01-12","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:1:0","tags":["Blog"],"title":"使用Hugo构建个人博客","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"2 安装和使用Hugo 安装Hugo：Installation | Hugo （建议下载extended版本） 将hugo.exe所在目录添加到环境变量 新建Hugo网站 hugo new site my_site 下载主题：（此处以LoveIt为例） git clone https://github.com/dillonzq/LoveIt.git my_site/themes/LoveIt 配置config.toml （可以将my_site/themes/LoveIt/exampleSite/config.toml复制到my_site/目录，并自行修改） 新建文章 cd my_site hugo new posts/first_post.md 在本地启动网站 hugo serve 去查看 http://localhost:1313 ","date":"2025-01-12","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:0","tags":["Blog"],"title":"使用Hugo构建个人博客","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"3 部署到Github Pages 构建网站 hugo 会生成一个 public 目录, 其中包含你网站的所有静态内容和资源。 将public初始化为git库，并提交至github ","date":"2025-01-12","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:3:0","tags":["Blog"],"title":"使用Hugo构建个人博客","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"4 在Markdown里引用本地图片 将本地图片存放在博客根目录的 static 目录中。 在markdown文件中按照如下格式引用图片。假设要引用路径为 static/img.png 的图片： ![](/img.png) 执行 hugo 并提交 ","date":"2025-01-12","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:4:0","tags":["Blog"],"title":"使用Hugo构建个人博客","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"X 参考 Stilig’s blog Yulin Lewis’ blog ","date":"2025-01-12","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:5:0","tags":["Blog"],"title":"使用Hugo构建个人博客","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}]